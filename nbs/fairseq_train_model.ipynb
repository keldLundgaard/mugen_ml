{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import os, sys, time, pickle\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "PROJECT_DIR = Path(sys.path[0])/\"..\"\n",
    "DATA_DIR = PROJECT_DIR/\"data\"\n",
    "SRC_DIR = PROJECT_DIR/\"src\"\n",
    "DEPS_DIR = PROJECT_DIR/\"deps\"\n",
    "\n",
    "sys.path.append(str(SRC_DIR))\n",
    "sys.path.append(str(DEPS_DIR))\n",
    "\n",
    "%pylab inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from fairseq_wav2vec import Wav2Vec2Config, Wav2Vec2Model\n",
    "import pandas as pd\n",
    "\n",
    "from mugen_train import (\n",
    "    musicDataset, IDX_to_GENRE, GENRE_TO_IDX, \n",
    "    get_music_data_loaders, GenreClassifier, get_batch_genre_one_hot,\n",
    "    get_num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jupyter nbextension enable --py widgetsnbextension\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wav2vec-model n_params: 95,356,288\n",
      "genre_classifier n_params: 6,450\n"
     ]
    }
   ],
   "source": [
    "top50_genre_samples_df = pd.read_csv(\"/n1Tb/sc_mp3_top50_genre_samples.tsv_gz\", compression='gzip', sep='\\t')\n",
    "\n",
    "train_loader, valid_loader = get_music_data_loaders(top50_genre_samples_df, cut=8e4)\n",
    "\n",
    "model = Wav2Vec2Model(Wav2Vec2Config)\n",
    "model = model.to(\"cuda\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.05, betas=(0.9,0.98), eps=1e-06, weight_decay=0.01, fused=True)\n",
    "\n",
    "feature_size = 128\n",
    "n_genres = 50\n",
    "\n",
    "t_specs = {\n",
    "#     \"d_model\": 128, \n",
    "    \"dim_feedforward\": 64, \n",
    "    \"num_decoder_layers\": 0,\n",
    "    \"num_encoder_layers\": 0,\n",
    "    \"nhead\": 1,\n",
    "}\n",
    "genre_classifier = GenreClassifier(n_genres, feature_size, t_specs=t_specs, use_transformer=False).to(\"cuda\")\n",
    "# genre_loss_model = GenreLoss(n_genres, feature_size, genre_classifier)\n",
    "\n",
    "print(f\"wav2vec-model n_params: {get_num_params(model):,d}\")\n",
    "print(f\"genre_classifier n_params: {get_num_params(genre_classifier):,d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_max_prop (0.4520392417907715, 0.5303441882133484)\n",
      "losses 0.6936724781990051 0.6936724781990051 0.20757219195365906\n",
      "min_max_prop (0.46279412508010864, 0.53092360496521)\n",
      "losses 0.6909421682357788 0.6909421682357788 18133940.0\n",
      "min_max_prop (0.003154048230499029, 0.9981392621994019)\n",
      "losses 1.0832147598266602 1.0832147598266602 1274364.25\n",
      "min_max_prop (0.0009914473630487919, 0.9979864358901978)\n",
      "losses 1.460135579109192 1.460135579109192 448180.6875\n",
      "min_max_prop (0.18479204177856445, 0.7586262226104736)\n",
      "losses 0.7335160374641418 0.7335160374641418 36.88273239135742\n",
      "min_max_prop (9.873410454019904e-05, 0.9999595880508423)\n",
      "losses 1.5500057935714722 1.5500057935714722 573716864.0\n",
      "min_max_prop (0.00033484408049844205, 0.9998441934585571)\n",
      "losses 1.3551312685012817 1.3551312685012817 2190111488.0\n",
      "min_max_prop (0.012995255179703236, 0.9794410467147827)\n",
      "losses 1.0988717079162598 1.0988717079162598 2588401664.0\n",
      "min_max_prop (0.0003633878950495273, 0.9998294115066528)\n",
      "losses 1.3832255601882935 1.3832255601882935 1683812608.0\n",
      "min_max_prop (0.11635273694992065, 0.897746205329895)\n",
      "losses 0.732214629650116 0.732214629650116 426660672.0\n",
      "min_max_prop (0.00013751635560765862, 0.9996631145477295)\n",
      "losses 1.8342961072921753 1.8342961072921753 18180084.0\n",
      "num_inf in output of model 2\n"
     ]
    }
   ],
   "source": [
    "data_loader = train_loader\n",
    "\n",
    "model.train()\n",
    "running_loss = 0.0\n",
    "losses = []\n",
    "for i, (batch, genres) in tqdm(enumerate(data_loader, 0), total=len(data_loader), disable=True):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(batch)\n",
    "    \n",
    "    num_inf = torch.sum(torch.isinf(outputs[\"x\"]))\n",
    "    \n",
    "    if num_inf:\n",
    "        print(f\"num_inf in output of model {num_inf}\")\n",
    "        break\n",
    "        \n",
    "    genre_props = genre_classifier(outputs[\"x\"])\n",
    "    min_max_prop = genre_props.min().to(\"cpu\").item(), genre_props.max().to(\"cpu\").item() \n",
    "    if np.isnan(min_max_prop[0]) or np.isnan(min_max_prop[1]):\n",
    "        print(\"np.isnan(min_max_prop[0]) or np.isnan(min_max_prop[1])\")\n",
    "        break\n",
    "    genre_loss = torch.nn.BCELoss()(genre_props, get_batch_genre_one_hot(genres, n_genres, \"cuda\"))\n",
    "\n",
    "    wav2vec_features_pen = outputs[\"features_pen\"]\n",
    "    \n",
    "    loss = genre_loss #+ 0.1 * wav2vec_features_pen\n",
    "    loss_item = loss.to(\"cpu\").item() \n",
    "    print(\"min_max_prop\", min_max_prop)\n",
    "    print(\"losses\", loss_item, genre_loss.to(\"cpu\").item(), wav2vec_features_pen.to(\"cpu\").item())    \n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    running_loss += loss_item\n",
    "    losses.append(loss_item)\n",
    "\n",
    "    out_is_inf = torch.isinf(outputs['x']).any().item()\n",
    "    if out_is_inf:\n",
    "        inf_values = torch.isinf(outputs['x']).sum() \n",
    "        print(f\"{inf_values} inf values in output\")\n",
    "        break    \n",
    "\n",
    "    for name, param in genre_classifier.named_parameters():\n",
    "        has_nan = torch.isnan(param).any()\n",
    "        has_inf = torch.isinf(param).any()\n",
    "\n",
    "        if has_nan or has_inf:\n",
    "            print(f\"genre_classifier {name} has_nan {has_nan} has_inf {has_inf}.\")\n",
    "            break        \n",
    "        \n",
    "    for name, param in model.named_parameters():\n",
    "        has_nan = torch.isnan(param).any()\n",
    "        has_inf = torch.isinf(param).any()\n",
    "\n",
    "        if has_nan or has_inf:\n",
    "            print(f\"Parameter {name} has_nan {has_nan} has_inf {has_inf}.\")\n",
    "            break\n",
    "\n",
    "    if has_nan or has_inf:\n",
    "        print(\"has_nan or has_inf\")\n",
    "        break\n",
    "    \n",
    "# return running_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-inf, device='cuda:0', grad_fn=<MinBackward1>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(outputs[\"x\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(param.shape)\n",
    "#     has_nan = torch.isnan(param).any()\n",
    "#     has_inf = torch.isinf(param).any()\n",
    "#     print(torch.min(param), torch.max(param))\n",
    "    if has_nan or has_inf:\n",
    "        print(f\"Parameter {name} has_nan {has_nan} has_inf {has_inf}.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(nan, nan)\n"
     ]
    }
   ],
   "source": [
    "genre_props = genre_classifier(outputs[\"x\"][:, 5:6, :])\n",
    "\n",
    "\n",
    "min_max_prop = genre_props.min().to(\"cpu\").item(), genre_props.max().to(\"cpu\").item()\n",
    "print(min_max_prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-inf, device='cuda:0', grad_fn=<MinBackward1>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(outputs[\"x\"][:, 5:6, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43moutputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "outputs[\"x\"][:, 5, :].to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-inf, device='cuda:0', grad_fn=<MinBackward1>),\n",
       " tensor(8.1407, device='cuda:0', grad_fn=<MaxBackward1>))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(outputs[\"x\"][:, 5, :]), torch.max(outputs[\"x\"][:, 5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 416,
       "width": 451
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import colors\n",
    "cmap = colors.ListedColormap(['red', 'blue', 'green', 'purple',])\n",
    "bounds = [-2,0,2]\n",
    "norm = colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(outputs[\"x\"][:, 5, :].to(\"cpu\").detach().numpy(), cmap=cmap, norm=norm);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([101, 12, 108])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[\"x\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.3394,  3.3260,  3.3887,  ...,  0.2598,  1.9368,  1.5712],\n",
       "        [ 3.9297,  4.0692,  0.6154,  ...,  3.6812,  3.9889,  0.7476],\n",
       "        [ 4.0207,  2.3219,  2.2242,  ...,  2.9346,  3.9889,  5.0196],\n",
       "        ...,\n",
       "        [ 3.5189,  3.3159,  0.6154,  ...,  3.3623,  2.1952,  4.0173],\n",
       "        [ 2.2961,  2.1823,  3.7294,  ...,  2.3960,  5.0137, -0.0347],\n",
       "        [ 3.5200,  3.3159,  5.5642,  ...,  3.9789,  3.9889,  4.0194]],\n",
       "       device='cuda:0', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[\"x\"][:, 5, :].view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5695, 0.3973, 0.7511, 0.1627, 0.6493, 0.3275, 0.0887, 0.7731, 0.8138,\n",
       "         0.5457, 0.0810, 0.5102, 0.7605, 0.8075, 0.7386, 0.0786, 0.8443, 0.5631,\n",
       "         0.9625, 0.6363, 0.1389, 0.7848, 0.5494, 0.8912, 0.9155, 0.9652, 0.8007,\n",
       "         0.6184, 0.6881, 0.5175, 0.7194, 0.7148, 0.8654, 0.9318, 0.4117, 0.7033,\n",
       "         0.8355, 0.1206, 0.2134, 0.9707, 0.3930, 0.7667, 0.0458, 0.1134, 0.5651,\n",
       "         0.2037, 0.4024, 0.5092, 0.7950, 0.0880],\n",
       "        [0.5764, 0.3751, 0.7448, 0.1401, 0.6579, 0.3414, 0.0751, 0.7744, 0.8169,\n",
       "         0.5502, 0.0834, 0.4983, 0.7798, 0.8178, 0.7527, 0.0738, 0.8536, 0.5810,\n",
       "         0.9687, 0.6560, 0.1303, 0.7900, 0.5575, 0.8974, 0.9208, 0.9704, 0.8066,\n",
       "         0.6329, 0.7021, 0.5072, 0.7239, 0.7074, 0.8692, 0.9336, 0.4017, 0.7012,\n",
       "         0.8367, 0.1165, 0.1997, 0.9742, 0.3990, 0.7774, 0.0422, 0.1075, 0.5703,\n",
       "         0.1799, 0.4140, 0.5024, 0.8082, 0.0783],\n",
       "        [0.5572, 0.4109, 0.7146, 0.1811, 0.6319, 0.3603, 0.1140, 0.7418, 0.7929,\n",
       "         0.5398, 0.1196, 0.4972, 0.7436, 0.7778, 0.7230, 0.1092, 0.8196, 0.5446,\n",
       "         0.9457, 0.6540, 0.1718, 0.7458, 0.5700, 0.8537, 0.8991, 0.9500, 0.7671,\n",
       "         0.5996, 0.6783, 0.4858, 0.6882, 0.6987, 0.8410, 0.9152, 0.4123, 0.6372,\n",
       "         0.7917, 0.1645, 0.2434, 0.9540, 0.4047, 0.7578, 0.0696, 0.1332, 0.5490,\n",
       "         0.2600, 0.3833, 0.5272, 0.7699, 0.1085],\n",
       "        [0.5660, 0.3690, 0.7255, 0.1716, 0.6633, 0.3655, 0.0908, 0.7669, 0.8086,\n",
       "         0.5388, 0.1000, 0.5018, 0.7573, 0.7858, 0.7446, 0.0854, 0.8440, 0.5640,\n",
       "         0.9609, 0.6413, 0.1569, 0.7756, 0.5305, 0.8810, 0.9085, 0.9625, 0.7974,\n",
       "         0.6166, 0.6889, 0.4993, 0.7035, 0.6960, 0.8518, 0.9186, 0.4046, 0.6911,\n",
       "         0.8214, 0.1313, 0.2240, 0.9657, 0.3972, 0.7590, 0.0522, 0.1211, 0.5478,\n",
       "         0.1922, 0.4122, 0.5073, 0.7870, 0.0899],\n",
       "        [0.5528, 0.4324, 0.7204, 0.1977, 0.6209, 0.3592, 0.1195, 0.7075, 0.7518,\n",
       "         0.5336, 0.1278, 0.4859, 0.7352, 0.7616, 0.6828, 0.1172, 0.8162, 0.6030,\n",
       "         0.9379, 0.6487, 0.1750, 0.7544, 0.5526, 0.8407, 0.8670, 0.9441, 0.7573,\n",
       "         0.5745, 0.6631, 0.4730, 0.6967, 0.6377, 0.8134, 0.8895, 0.4382, 0.6835,\n",
       "         0.7995, 0.1719, 0.2199, 0.9471, 0.4136, 0.7421, 0.0855, 0.1570, 0.5212,\n",
       "         0.2574, 0.4342, 0.5115, 0.7609, 0.1116],\n",
       "        [0.0000, 0.0000,    nan, 1.0000,    nan, 0.0000,    nan, 0.0000,    nan,\n",
       "            nan, 0.0000,    nan, 1.0000,    nan,    nan,    nan,    nan, 0.0000,\n",
       "         0.0000, 0.0000,    nan,    nan, 0.0000,    nan, 1.0000,    nan,    nan,\n",
       "            nan, 0.0000, 1.0000, 1.0000,    nan,    nan, 0.0000, 0.0000,    nan,\n",
       "         0.0000, 0.0000,    nan,    nan, 0.0000,    nan, 1.0000, 0.0000,    nan,\n",
       "            nan,    nan,    nan, 1.0000,    nan],\n",
       "        [0.5574, 0.4236, 0.6858, 0.1888, 0.6368, 0.3372, 0.1470, 0.7306, 0.7797,\n",
       "         0.5349, 0.1411, 0.4761, 0.6992, 0.7838, 0.6951, 0.1164, 0.8017, 0.5402,\n",
       "         0.9281, 0.6147, 0.1784, 0.7189, 0.5601, 0.8511, 0.8740, 0.9337, 0.7619,\n",
       "         0.5813, 0.6677, 0.4566, 0.6572, 0.6662, 0.8072, 0.8790, 0.4469, 0.6317,\n",
       "         0.7757, 0.2056, 0.2653, 0.9436, 0.4048, 0.7457, 0.0856, 0.1465, 0.5295,\n",
       "         0.2534, 0.4030, 0.4782, 0.7630, 0.1384],\n",
       "        [0.5993, 0.4246, 0.7498, 0.1582, 0.6309, 0.3447, 0.0971, 0.7217, 0.7919,\n",
       "         0.5515, 0.1160, 0.4616, 0.7504, 0.7861, 0.7492, 0.1043, 0.8333, 0.5494,\n",
       "         0.9497, 0.6659, 0.1683, 0.7723, 0.5694, 0.8633, 0.8964, 0.9572, 0.7903,\n",
       "         0.5941, 0.6474, 0.4944, 0.7113, 0.6701, 0.8429, 0.9133, 0.4174, 0.6572,\n",
       "         0.7977, 0.1510, 0.2202, 0.9630, 0.4172, 0.7519, 0.0615, 0.1178, 0.5583,\n",
       "         0.2168, 0.4252, 0.5115, 0.7930, 0.0930],\n",
       "        [0.5665, 0.3698, 0.7511, 0.1412, 0.6648, 0.3377, 0.0776, 0.7731, 0.8274,\n",
       "         0.5528, 0.0790, 0.4971, 0.7754, 0.8167, 0.7601, 0.0676, 0.8593, 0.5661,\n",
       "         0.9698, 0.6558, 0.1218, 0.7961, 0.5628, 0.9012, 0.9267, 0.9714, 0.8165,\n",
       "         0.6317, 0.7033, 0.5113, 0.7165, 0.7183, 0.8790, 0.9406, 0.3944, 0.6972,\n",
       "         0.8415, 0.1121, 0.2001, 0.9767, 0.3837, 0.7754, 0.0391, 0.0984, 0.5576,\n",
       "         0.1838, 0.3940, 0.5127, 0.8145, 0.0792],\n",
       "        [0.5712, 0.3792, 0.7458, 0.1481, 0.6623, 0.3387, 0.0812, 0.7714, 0.8181,\n",
       "         0.5524, 0.0827, 0.4931, 0.7699, 0.8117, 0.7565, 0.0713, 0.8511, 0.5626,\n",
       "         0.9678, 0.6489, 0.1273, 0.7916, 0.5665, 0.8993, 0.9216, 0.9693, 0.8139,\n",
       "         0.6349, 0.7012, 0.5083, 0.7165, 0.7161, 0.8720, 0.9382, 0.4115, 0.6909,\n",
       "         0.8429, 0.1214, 0.2147, 0.9738, 0.3861, 0.7713, 0.0428, 0.1037, 0.5654,\n",
       "         0.1899, 0.4001, 0.5054, 0.8044, 0.0819],\n",
       "        [0.5703, 0.3766, 0.7563, 0.1403, 0.6664, 0.3375, 0.0714, 0.7838, 0.8256,\n",
       "         0.5552, 0.0778, 0.5003, 0.7787, 0.8214, 0.7621, 0.0672, 0.8591, 0.5672,\n",
       "         0.9705, 0.6525, 0.1206, 0.7961, 0.5652, 0.9035, 0.9294, 0.9729, 0.8152,\n",
       "         0.6349, 0.6987, 0.5129, 0.7214, 0.7217, 0.8792, 0.9428, 0.3978, 0.7000,\n",
       "         0.8448, 0.1124, 0.2023, 0.9771, 0.3900, 0.7816, 0.0386, 0.0980, 0.5594,\n",
       "         0.1774, 0.3942, 0.5148, 0.8145, 0.0767],\n",
       "        [0.5551, 0.3852, 0.7236, 0.1456, 0.6520, 0.3462, 0.0860, 0.7667, 0.8134,\n",
       "         0.5527, 0.0844, 0.4997, 0.7688, 0.8119, 0.7415, 0.0790, 0.8506, 0.5561,\n",
       "         0.9640, 0.6322, 0.1310, 0.7893, 0.5729, 0.8936, 0.9204, 0.9679, 0.8064,\n",
       "         0.6358, 0.7034, 0.5092, 0.7184, 0.7245, 0.8727, 0.9351, 0.4063, 0.6982,\n",
       "         0.8366, 0.1188, 0.2138, 0.9736, 0.3969, 0.7741, 0.0452, 0.1088, 0.5513,\n",
       "         0.1924, 0.4033, 0.5197, 0.7974, 0.0814]], device='cuda:0',\n",
       "       grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0410, -0.0627, -0.0819,  ..., -0.0716,  0.0092,  0.0186],\n",
      "        [ 0.0190, -0.0306, -0.0257,  ..., -0.0130,  0.0600,  0.0464],\n",
      "        [-0.0496, -0.0418,  0.0333,  ..., -0.0691, -0.0629,  0.0027],\n",
      "        ...,\n",
      "        [-0.0593,  0.0810,  0.0043,  ...,  0.0623,  0.0437,  0.0159],\n",
      "        [-0.0800,  0.0101,  0.0367,  ...,  0.0093,  0.0865,  0.0833],\n",
      "        [ 0.0506,  0.0068, -0.0344,  ..., -0.0049, -0.0750, -0.0531]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0666,  0.0769, -0.0589,  0.0088,  0.0770, -0.0631,  0.0296, -0.0852,\n",
      "        -0.0138,  0.0382, -0.0125,  0.0260,  0.0037,  0.0587, -0.0495,  0.0227,\n",
      "        -0.0517, -0.0357, -0.0754,  0.0814,  0.0666,  0.0005,  0.0072, -0.0829,\n",
      "         0.0205,  0.0181, -0.0020, -0.0139,  0.0669, -0.0546,  0.0538,  0.0003,\n",
      "         0.0427, -0.0369,  0.0525, -0.0223, -0.0311, -0.0612, -0.0653, -0.0865,\n",
      "        -0.0715, -0.0029,  0.0690, -0.0655,  0.0234,  0.0476,  0.0725, -0.0571,\n",
      "         0.0848, -0.0553], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for name, param in genre_classifier.named_parameters():\n",
    "    print(param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([384])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in genre_classifier.named_parameters():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenreClassifier(\n",
       "  (genre_transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (3): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (4): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (5): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=128, out_features=50, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_classifier.named_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.1734, -2.1676, -2.6694,  ..., -1.6409, -2.1309, -2.1816],\n",
       "         [-2.1533, -2.3232, -2.0918,  ..., -2.9556, -2.3380, -2.1146],\n",
       "         [-2.5770, -2.6286, -0.7590,  ..., -1.9916, -1.9645, -2.6201],\n",
       "         ...,\n",
       "         [-2.4726, -1.3606, -1.9379,  ..., -2.5782, -1.4332, -1.1699],\n",
       "         [ 3.0867,  3.1184,  3.0901,  ...,  0.1815,  1.0042, -0.1994],\n",
       "         [ 3.1160,  3.1264,  3.1052,  ...,  2.1382,  2.1611,  2.7250]],\n",
       "\n",
       "        [[-1.9833, -1.8586,  2.5696,  ..., -2.3124, -2.1286, -2.6733],\n",
       "         [-1.7463,  1.7897, -2.0662,  ..., -1.1333, -1.7055, -1.6615],\n",
       "         [-1.9266, -2.9367, -0.9724,  ..., -2.1112, -2.5451, -1.5186],\n",
       "         ...,\n",
       "         [-2.1730, -1.3378, -2.7757,  ..., -2.1860, -2.6792, -2.5119],\n",
       "         [-2.0726, -1.6207, -1.8092,  ..., -2.1611, -1.9689, -0.2427],\n",
       "         [-2.6555, -2.0919,  2.6173,  ...,  0.3920, -1.8350, -2.0178]],\n",
       "\n",
       "        [[-2.1359, -2.1553, -2.1664,  ..., -2.1740, -1.8800, -2.1877],\n",
       "         [-0.7386, -2.2217, -2.5511,  ..., -1.3815, -2.3300, -1.1581],\n",
       "         [-1.6017, -1.4960, -2.0291,  ...,  0.7950, -2.5966, -1.9330],\n",
       "         ...,\n",
       "         [-2.0926, -2.5919, -2.0055,  ..., -1.9140, -2.3628, -2.0294],\n",
       "         [ 1.2556,  0.7983,    -inf,  ...,  3.1093, -1.8712, -2.3302],\n",
       "         [-2.1542, -2.0974, -2.1854,  ...,  1.1654,  2.0721,  1.1635]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.2157, -2.1928, -2.4254,  ...,  1.7007, -2.6574,  1.1041],\n",
       "         [-1.4806, -0.7675, -2.0907,  ..., -1.4188, -1.6532,  1.9627],\n",
       "         [-0.7178, -2.3475, -1.8771,  ..., -1.6531, -1.5783, -2.6615],\n",
       "         ...,\n",
       "         [-1.8408, -1.3378, -1.8153,  ..., -1.8503, -2.3628, -1.6556],\n",
       "         [-2.2447, -2.1398, -2.4889,  ..., -1.1697,  0.3543, -0.2427],\n",
       "         [ 0.2554,  0.3121, -2.1375,  ...,  0.5911,  0.5987,  0.4760]],\n",
       "\n",
       "        [[-2.1505, -1.5378, -1.9783,  ..., -1.6417, -2.7739, -2.5177],\n",
       "         [-2.8732, -1.7424, -1.6525,  ..., -2.2908, -2.5798, -2.3499],\n",
       "         [-1.4598, -2.6225, -1.0288,  ..., -1.9135, -1.3216, -1.9487],\n",
       "         ...,\n",
       "         [-1.8709, -2.0243, -1.3013,  ..., -2.2648, -2.3628, -2.5119],\n",
       "         [-0.3957, -1.6207, -2.3779,  ..., -2.1780,  0.9849, -0.7465],\n",
       "         [-2.0756,  1.4850,  1.1200,  ...,  3.1155,  0.4164, -0.2787]],\n",
       "\n",
       "        [[-2.3809, -1.8880, -2.3172,  ..., -1.4978, -2.2577,  1.3399],\n",
       "         [-2.5348, -1.3648, -1.1724,  ...,  1.4080, -2.2414,  0.3154],\n",
       "         [ 1.4654, -2.7415,  0.0962,  ..., -2.0860, -1.1561, -1.5307],\n",
       "         ...,\n",
       "         [-1.9385, -2.0639, -1.9833,  ..., -1.4260, -2.3628, -2.1101],\n",
       "         [-2.2491, -1.4544, -2.0901,  ..., -1.9094,  0.2436, -0.2151],\n",
       "         [   -inf, -2.2590, -2.1998,  ..., -1.4567, -1.8782,  1.5472]]],\n",
       "       device='cuda:0', grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[\"x\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(min_max_prop[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.980274200439453 0.7756848335266113 0.22342604398727417\n"
     ]
    }
   ],
   "source": [
    "print(loss_item, genre_loss.to(\"cpu\").item(), wav2vec_features_pen.to(\"cpu\").item())    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/keld/miniconda3/envs/mugen_ml/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m(197)\u001b[0;36mbackward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    195 \u001b[0;31m    \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    196 \u001b[0;31m    \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 197 \u001b[0;31m    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0m\u001b[0;32m    198 \u001b[0;31m        \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    199 \u001b[0;31m        allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/keld/miniconda3/envs/mugen_ml/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m(488)\u001b[0;36mbackward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    486 \u001b[0;31m                \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    487 \u001b[0;31m            )\n",
      "\u001b[0m\u001b[0;32m--> 488 \u001b[0;31m        torch.autograd.backward(\n",
      "\u001b[0m\u001b[0;32m    489 \u001b[0;31m            \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    490 \u001b[0;31m        )\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/ipykernel_1546931/969730788.py\u001b[0m(16)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     14 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     15 \u001b[0;31m    \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgenre_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mwav2vec_features_pen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 16 \u001b[0;31m    \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     17 \u001b[0;31m    \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     18 \u001b[0;31m    \u001b[0mloss_item\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** RuntimeError: numel: integer multiplication overflow\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Oldest frame\n"
     ]
    }
   ],
   "source": [
    "%debug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object <class 'ellipsis'> should have `state_dict` method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m lr_finder \u001b[38;5;241m=\u001b[39m FastaiLRFinder()\n\u001b[1;32m      8\u001b[0m to_save \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m\"\u001b[39m: optimizer}\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m lr_finder\u001b[38;5;241m.\u001b[39mattach(trainer, to_save\u001b[38;5;241m=\u001b[39mto_save) \u001b[38;5;28;01mas\u001b[39;00m trainer_with_lr_finder:\n\u001b[1;32m     11\u001b[0m     trainer_with_lr_finder\u001b[38;5;241m.\u001b[39mrun(dataloader)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Get lr_finder results\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mugen_ml/lib/python3.9/contextlib.py:119\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/mugen_ml/lib/python3.9/site-packages/ignite/handlers/lr_finder.py:425\u001b[0m, in \u001b[0;36mFastaiLRFinder.attach\u001b[0;34m(self, trainer, to_save, output_transform, num_iter, start_lr, end_lr, step_mode, smooth_f, diverge_th)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(to_save, Mapping):\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument to_save should be a mapping, but given \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(to_save)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 425\u001b[0m \u001b[43mCheckpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_save\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstate_dict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    426\u001b[0m Checkpoint\u001b[38;5;241m.\u001b[39m_check_objects(to_save, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_state_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m to_save:\n",
      "File \u001b[0;32m~/miniconda3/envs/mugen_ml/lib/python3.9/site-packages/ignite/handlers/checkpoint.py:544\u001b[0m, in \u001b[0;36mCheckpoint._check_objects\u001b[0;34m(objs, attr)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, obj \u001b[38;5;129;01min\u001b[39;00m objs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    543\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(obj, attr):\n\u001b[0;32m--> 544\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mObject \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m should have `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object <class 'ellipsis'> should have `state_dict` method"
     ]
    }
   ],
   "source": [
    "from ignite.handlers import FastaiLRFinder\n",
    "\n",
    "trainer = ...\n",
    "model = ...\n",
    "optimizer = ...\n",
    "\n",
    "lr_finder = FastaiLRFinder()\n",
    "to_save = {\"model\": model, \"optimizer\": optimizer}\n",
    "\n",
    "with lr_finder.attach(trainer, to_save=to_save) as trainer_with_lr_finder:\n",
    "    trainer_with_lr_finder.run(dataloader)\n",
    "\n",
    "# Get lr_finder results\n",
    "lr_finder.get_results()\n",
    "\n",
    "# Plot lr_finder results (requires matplotlib)\n",
    "lr_finder.plot()\n",
    "\n",
    "# get lr_finder suggestion for lr\n",
    "lr_finder.lr_suggestion()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2 -- with small update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 8334/8334 [54:23<00:00,  2.55it/s]\n",
      "100%|| 17/17 [00:04<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000 train_loss: 0.0000 val_loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 8334/8334 [54:39<00:00,  2.54it/s]\n",
      "100%|| 17/17 [00:04<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001 train_loss: 0.0000 val_loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 8334/8334 [54:43<00:00,  2.54it/s]\n",
      "100%|| 17/17 [00:04<00:00,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "002 train_loss: 0.0000 val_loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loses = []\n",
    "val_loses = []\n",
    "for epoch in range(3):\n",
    "    train_loss = train(model, optimizer, train_loader)\n",
    "    val_loss = validation(model, valid_loader)\n",
    "    print(f\"{epoch:03d} train_loss: {train_loss:0.4f} val_loss: {val_loss:0.4f}\")\n",
    "    train_loses.append(train_loss)\n",
    "    val_loses.append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loses, label=\"train_loses\");\n",
    "plt.plot(val_loses, label=\"val_loses\");\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1 -- diverging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 8334/8334 [54:19<00:00,  2.56it/s]\n",
      "100%|| 17/17 [00:04<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000 train_loss: 0.0000 val_loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 8334/8334 [54:35<00:00,  2.54it/s]\n",
      "100%|| 17/17 [00:04<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001 train_loss: 0.0000 val_loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 8334/8334 [54:34<00:00,  2.55it/s]\n",
      "100%|| 17/17 [00:04<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "002 train_loss: 0.0000 val_loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 8334/8334 [54:29<00:00,  2.55it/s]\n",
      "100%|| 17/17 [00:04<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "003 train_loss: 0.0000 val_loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 8334/8334 [54:29<00:00,  2.55it/s]\n",
      "100%|| 17/17 [00:04<00:00,  4.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "004 train_loss: 0.0000 val_loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loses = []\n",
    "val_loses = []\n",
    "for epoch in range(5):\n",
    "    train_loss = train(model, optimizer, train_loader)\n",
    "    val_loss = validation(model, valid_loader)\n",
    "    print(f\"{epoch:03d} train_loss: {train_loss:0.4f} val_loss: {val_loss:0.4f}\")\n",
    "    train_loses.append(train_loss)\n",
    "    val_loses.append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scratchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    train_loss = train(model, optimizer, criterion, train_loader)\n",
    "    print(f\"Epoch {epoch+1}, train loss: {train_loss:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch in enumerate(top50_dataloader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.forward(sample_bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 120000])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_bs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 273024])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                     | 0/17 [00:02<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "running_loss = 0.0\n",
    "for i, (batch, genres) in tqdm(enumerate(valid_loader, 0), total=len(valid_loader)):\n",
    "    outputs = model(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([101, 12, 120])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs['x'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.music_collate_fn_wrap.<locals>.music_collate_fn(x)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mugen_ml",
   "language": "python",
   "name": "mugen_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

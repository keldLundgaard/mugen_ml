{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keld/miniconda3/envs/mugen_ml/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, sys, time, pickle\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "PROJECT_DIR = Path(sys.path[0])/\"..\"\n",
    "DATA_DIR = PROJECT_DIR/\"data\"\n",
    "SRC_DIR = PROJECT_DIR/\"src\"\n",
    "DEPS_DIR = PROJECT_DIR/\"deps\"\n",
    "\n",
    "sys.path.append(str(SRC_DIR))\n",
    "sys.path.append(str(DEPS_DIR))\n",
    "\n",
    "%pylab inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from fairseq_wav2vec import Wav2Vec2Config, Wav2Vec2Model\n",
    "import pandas as pd\n",
    "\n",
    "from mugen_train import musicDataset, IDX_to_GENRE, GENRE_TO_IDX, get_music_data_loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "top50_genre_samples_df = pd.read_csv(\"/n1Tb/sc_mp3_top50_genre_samples.tsv_gz\", compression='gzip', sep='\\t')\n",
    "\n",
    "train_loader, valid_loader = get_music_data_loaders(top50_genre_samples_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Wav2Vec2Model(Wav2Vec2Config)\n",
    "model = model.to(\"cuda\")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, betas=(0.9,0.98), eps=1e-06, weight_decay=0.01, fused=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model._parameters.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = train_loader\n",
    "\n",
    "model.train()\n",
    "running_loss = 0.0\n",
    "losses = []\n",
    "for i, (batch, genres) in tqdm(enumerate(data_loader, 0), total=len(data_loader), disable=True):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(batch)\n",
    "    loss = outputs[\"features_pen\"]\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_item = loss.to(\"cpu\").item() \n",
    "    running_loss += loss_item\n",
    "    losses.append(loss_item)\n",
    "    print(loss_item)\n",
    "    \n",
    "    param_names = list(model.state_dict().keys())\n",
    "    for name, param in model.named_parameters():\n",
    "        has_nan = torch.isnan(param).any()\n",
    "        has_inf = torch.isinf(param).any()\n",
    "\n",
    "        if has_nan or has_inf:\n",
    "            print(f\"Parameter {name} has_nan {has_nan} has_inf {has_inf}.\")\n",
    "            break\n",
    "    if has_nan or has_inf:\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "# return running_loss / len(data_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.named_parameters at 0x7ff4728670b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013600117526948452"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/ipykernel_1539100/1953120967.py\u001b[0m(12)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      9 \u001b[0;31m    \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     10 \u001b[0;31m    \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     11 \u001b[0;31m    \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 12 \u001b[0;31m    \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     13 \u001b[0;31m\u001b[0;32mreturn\u001b[0m \u001b[0mrunning_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  q\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "PYDEV DEBUGGER WARNING:\n",
      "sys.settrace() should not be used when the debugger is being used.\n",
      "This may cause the debugger to stop working correctly.\n",
      "If this is needed, please check: \n",
      "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
      "to see how to restore the debug tracing back correctly.\n",
      "Call Location:\n",
      "  File \"/home/keld/miniconda3/envs/mugen_ml/lib/python3.9/bdb.py\", line 359, in set_quit\n",
      "    sys.settrace(None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object <class 'ellipsis'> should have `state_dict` method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m lr_finder \u001b[38;5;241m=\u001b[39m FastaiLRFinder()\n\u001b[1;32m      8\u001b[0m to_save \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m\"\u001b[39m: optimizer}\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m lr_finder\u001b[38;5;241m.\u001b[39mattach(trainer, to_save\u001b[38;5;241m=\u001b[39mto_save) \u001b[38;5;28;01mas\u001b[39;00m trainer_with_lr_finder:\n\u001b[1;32m     11\u001b[0m     trainer_with_lr_finder\u001b[38;5;241m.\u001b[39mrun(dataloader)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Get lr_finder results\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mugen_ml/lib/python3.9/contextlib.py:119\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/mugen_ml/lib/python3.9/site-packages/ignite/handlers/lr_finder.py:425\u001b[0m, in \u001b[0;36mFastaiLRFinder.attach\u001b[0;34m(self, trainer, to_save, output_transform, num_iter, start_lr, end_lr, step_mode, smooth_f, diverge_th)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(to_save, Mapping):\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument to_save should be a mapping, but given \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(to_save)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 425\u001b[0m \u001b[43mCheckpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_save\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstate_dict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    426\u001b[0m Checkpoint\u001b[38;5;241m.\u001b[39m_check_objects(to_save, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_state_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m to_save:\n",
      "File \u001b[0;32m~/miniconda3/envs/mugen_ml/lib/python3.9/site-packages/ignite/handlers/checkpoint.py:544\u001b[0m, in \u001b[0;36mCheckpoint._check_objects\u001b[0;34m(objs, attr)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, obj \u001b[38;5;129;01min\u001b[39;00m objs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    543\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(obj, attr):\n\u001b[0;32m--> 544\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mObject \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m should have `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object <class 'ellipsis'> should have `state_dict` method"
     ]
    }
   ],
   "source": [
    "from ignite.handlers import FastaiLRFinder\n",
    "\n",
    "trainer = ...\n",
    "model = ...\n",
    "optimizer = ...\n",
    "\n",
    "lr_finder = FastaiLRFinder()\n",
    "to_save = {\"model\": model, \"optimizer\": optimizer}\n",
    "\n",
    "with lr_finder.attach(trainer, to_save=to_save) as trainer_with_lr_finder:\n",
    "    trainer_with_lr_finder.run(dataloader)\n",
    "\n",
    "# Get lr_finder results\n",
    "lr_finder.get_results()\n",
    "\n",
    "# Plot lr_finder results (requires matplotlib)\n",
    "lr_finder.plot()\n",
    "\n",
    "# get lr_finder suggestion for lr\n",
    "lr_finder.lr_suggestion()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2 -- with small update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 8334/8334 [54:23<00:00,  2.55it/s]\n",
      "100%|████████████████████████████████████████████████████████████| 17/17 [00:04<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000 train_loss: 0.0000 val_loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 8334/8334 [54:39<00:00,  2.54it/s]\n",
      "100%|████████████████████████████████████████████████████████████| 17/17 [00:04<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001 train_loss: 0.0000 val_loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 8334/8334 [54:43<00:00,  2.54it/s]\n",
      "100%|████████████████████████████████████████████████████████████| 17/17 [00:04<00:00,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "002 train_loss: 0.0000 val_loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loses = []\n",
    "val_loses = []\n",
    "for epoch in range(3):\n",
    "    train_loss = train(model, optimizer, train_loader)\n",
    "    val_loss = validation(model, valid_loader)\n",
    "    print(f\"{epoch:03d} train_loss: {train_loss:0.4f} val_loss: {val_loss:0.4f}\")\n",
    "    train_loses.append(train_loss)\n",
    "    val_loses.append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loses, label=\"train_loses\");\n",
    "plt.plot(val_loses, label=\"val_loses\");\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1 -- diverging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 8334/8334 [54:19<00:00,  2.56it/s]\n",
      "100%|████████████████████████████████████████████████████████████| 17/17 [00:04<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000 train_loss: 0.0000 val_loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 8334/8334 [54:35<00:00,  2.54it/s]\n",
      "100%|████████████████████████████████████████████████████████████| 17/17 [00:04<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001 train_loss: 0.0000 val_loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 8334/8334 [54:34<00:00,  2.55it/s]\n",
      "100%|████████████████████████████████████████████████████████████| 17/17 [00:04<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "002 train_loss: 0.0000 val_loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 8334/8334 [54:29<00:00,  2.55it/s]\n",
      "100%|████████████████████████████████████████████████████████████| 17/17 [00:04<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "003 train_loss: 0.0000 val_loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 8334/8334 [54:29<00:00,  2.55it/s]\n",
      "100%|████████████████████████████████████████████████████████████| 17/17 [00:04<00:00,  4.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "004 train_loss: 0.0000 val_loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loses = []\n",
    "val_loses = []\n",
    "for epoch in range(5):\n",
    "    train_loss = train(model, optimizer, train_loader)\n",
    "    val_loss = validation(model, valid_loader)\n",
    "    print(f\"{epoch:03d} train_loss: {train_loss:0.4f} val_loss: {val_loss:0.4f}\")\n",
    "    train_loses.append(train_loss)\n",
    "    val_loses.append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scratchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    train_loss = train(model, optimizer, criterion, train_loader)\n",
    "    print(f\"Epoch {epoch+1}, train loss: {train_loss:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch in enumerate(top50_dataloader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.forward(sample_bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 120000])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_bs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 273024])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                     | 0/17 [00:02<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "running_loss = 0.0\n",
    "for i, (batch, genres) in tqdm(enumerate(valid_loader, 0), total=len(valid_loader)):\n",
    "    outputs = model(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([101, 12, 120])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs['x'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.music_collate_fn_wrap.<locals>.music_collate_fn(x)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mugen_ml",
   "language": "python",
   "name": "mugen_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import os, sys, time, pickle\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from IPython.display import Audio\n",
    "\n",
    "PROJECT_DIR = Path(sys.path[0])/\"..\"\n",
    "DATA_DIR = PROJECT_DIR/\"data\"\n",
    "SRC_DIR = PROJECT_DIR/\"src\"\n",
    "DEPS_DIR = PROJECT_DIR/\"deps\"\n",
    "\n",
    "sys.path.append(str(SRC_DIR))\n",
    "sys.path.append(str(DEPS_DIR))\n",
    "\n",
    "%pylab inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from fairseq_wav2vec import Wav2Vec2Config, Wav2Vec2Model\n",
    "import pandas as pd\n",
    "\n",
    "from mugen_train import (\n",
    "    musicDataset, IDX_to_GENRE, GENRE_TO_IDX, \n",
    "    get_music_data_loaders, GenreClassifier, get_batch_genre_one_hot,\n",
    "    MusicCNN,\n",
    "    get_num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_size = 128\n",
    "n_genres = 50\n",
    "\n",
    "top50_genre_samples_df = pd.read_csv(\"/n1Tb/sc_mp3_top50_genre_samples.tsv_gz\", compression='gzip', sep='\\t')\n",
    "\n",
    "train_loader, valid_loader = get_music_data_loaders(top50_genre_samples_df, cut=8e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wav2vec-model n_params: 95,356,288\n",
      "genre_classifier n_params: 6,450\n"
     ]
    }
   ],
   "source": [
    "model = Wav2Vec2Model(Wav2Vec2Config)\n",
    "model = model.to(\"cuda\")\n",
    "\n",
    "t_specs = {\n",
    "#     \"d_model\": 128, \n",
    "    \"dim_feedforward\": 64, \n",
    "    \"num_decoder_layers\": 0,\n",
    "    \"num_encoder_layers\": 0,\n",
    "    \"nhead\": 1,\n",
    "}\n",
    "genre_classifier = GenreClassifier(n_genres, feature_size, t_specs=t_specs, use_transformer=False).to(\"cuda\")\n",
    "# genre_loss_model = GenreLoss(n_genres, feature_size, genre_classifier)\n",
    "\n",
    "print(f\"wav2vec-model n_params: {get_num_params(model):,d}\")\n",
    "print(f\"genre_classifier n_params: {get_num_params(genre_classifier):,d}\")\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.05, betas=(0.9,0.98), eps=1e-06, weight_decay=0.01, fused=True)\n",
    "optimizer = torch.optim.Adam(genre_classifier.parameters(), lr=0.005, betas=(0.9,0.98), eps=1e-06, weight_decay=0.01, fused=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_inf in output of model 4\n",
      "Num of ignored samples: 1\n",
      "4 inf values in output\n"
     ]
    }
   ],
   "source": [
    "debug = False\n",
    "data_loader = train_loader\n",
    "\n",
    "model.train()\n",
    "running_loss = 0.0\n",
    "losses = []\n",
    "for i, (batch, genres) in tqdm(enumerate(data_loader, 0), total=len(data_loader), disable=~debug):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(batch)\n",
    "    \n",
    "    x = outputs[\"x\"]\n",
    "    num_inf = torch.sum(torch.isinf(x))\n",
    "    \n",
    "    if num_inf:\n",
    "        print(f\"num_inf in output of model {num_inf}\")\n",
    "        \n",
    "        ignore_samples = torch.where(x.isinf())[1].unique()\n",
    "        print(f\"Num of ignored samples: {len(ignore_samples)}\")\n",
    "        filter_samples = [i not in ignore_samples for i in range(x.shape[1])]\n",
    "        \n",
    "        x = x[:, filter_samples, :]\n",
    "        \n",
    "        genres = [genre for i, genre in enumerate(genres) if i not in ignore_samples]\n",
    "\n",
    "    # discard where there is inf values \n",
    "        \n",
    "    genre_props = genre_classifier(x)\n",
    "    min_max_prop = genre_props.min().to(\"cpu\").item(), genre_props.max().to(\"cpu\").item() \n",
    "    if np.isnan(min_max_prop[0]) or np.isnan(min_max_prop[1]):\n",
    "        print(\"np.isnan(min_max_prop[0]) or np.isnan(min_max_prop[1])\")\n",
    "        break\n",
    "    genre_loss = torch.nn.BCELoss()(genre_props, get_batch_genre_one_hot(genres, n_genres, \"cuda\"))\n",
    "\n",
    "    wav2vec_features_pen = outputs[\"features_pen\"]\n",
    "    \n",
    "    loss = genre_loss #+ 0.1 * wav2vec_features_pen\n",
    "    loss_item = loss.to(\"cpu\").item() \n",
    "    if debug:\n",
    "        print(\"min_max_prop\", min_max_prop)\n",
    "        print(\"losses\", loss_item, genre_loss.to(\"cpu\").item(), wav2vec_features_pen.to(\"cpu\").item())    \n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    running_loss += loss_item\n",
    "    losses.append(loss_item)\n",
    "\n",
    "    out_is_inf = torch.isinf(x).any().item()\n",
    "    if out_is_inf:\n",
    "        inf_values = torch.isinf(x).sum() \n",
    "        print(f\"{inf_values} inf values in output\")\n",
    "        break    \n",
    "\n",
    "    for name, param in genre_classifier.named_parameters():\n",
    "        has_nan = torch.isnan(param).any()\n",
    "        has_inf = torch.isinf(param).any()\n",
    "\n",
    "        if has_nan or has_inf:\n",
    "            print(f\"genre_classifier {name} has_nan {has_nan} has_inf {has_inf}.\")\n",
    "            break        \n",
    "        \n",
    "    for name, param in model.named_parameters():\n",
    "        has_nan = torch.isnan(param).any()\n",
    "        has_inf = torch.isinf(param).any()\n",
    "\n",
    "        if has_nan or has_inf:\n",
    "            print(f\"Parameter {name} has_nan {has_nan} has_inf {has_inf}.\")\n",
    "            break\n",
    "\n",
    "    if has_nan or has_inf:\n",
    "        print(\"has_nan or has_inf\")\n",
    "        break\n",
    "    \n",
    "# return running_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(genre_props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 37, 11, 29, 21, 5, 22, 6, 10, 36, 47, 39]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "ignore_samples = torch.where(outputs[\"x\"].isinf())[1].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "for x in ignore_samples.to(\"cpu\"):\n",
    "    print(x.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ignore_samples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mignore_samples\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ignore_samples' is not defined"
     ]
    }
   ],
   "source": [
    "ignore_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, True, True, True, True, True, True, True, False, True, True]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([101, 12, 94])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[\"x\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9], device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ignore_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = train_loader\n",
    "\n",
    "model.train()\n",
    "running_loss = 0.0\n",
    "losses = []\n",
    "for i, (batch, genres) in tqdm(enumerate(data_loader, 0), total=len(data_loader), disable=True):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (batch, genres) \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(\u001b[43mdata_loader\u001b[49m, \u001b[38;5;241m0\u001b[39m), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(data_loader), disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_loader' is not defined"
     ]
    }
   ],
   "source": [
    "for i, (batch, genres) in tqdm(enumerate(data_loader, 0), total=len(data_loader), disable=True):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio(batch[12].to(\"cpu\").detach().numpy(), rate=44100, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import colors\n",
    "# cmap = colors.ListedColormap(['red', 'blue', 'green', 'purple',])\n",
    "# bounds = [-2,0,2]\n",
    "# norm = colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.imshow(outputs[\"x\"][:, 5, :].to(\"cpu\").detach().numpy(), cmap=cmap, norm=norm);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 1.5653e-02,  1.0166e-02,  1.3567e-02,  ..., -1.4283e-03,\n",
      "         -3.4696e-05, -1.8214e-03],\n",
      "        [ 1.4348e-02,  1.4168e-02,  1.3006e-02,  ..., -2.0981e-04,\n",
      "          1.5393e-03, -1.8361e-03],\n",
      "        [ 7.3778e-03,  1.2378e-02,  8.1439e-03,  ...,  6.5706e-04,\n",
      "         -1.8284e-03,  7.1113e-04],\n",
      "        ...,\n",
      "        [ 1.4650e-02,  1.1347e-02,  1.1165e-02,  ...,  2.6091e-04,\n",
      "         -2.0520e-04,  6.1813e-05],\n",
      "        [ 1.1922e-02,  1.2531e-02,  1.1692e-02,  ...,  9.5847e-04,\n",
      "         -1.7996e-04, -9.5097e-05],\n",
      "        [ 1.3669e-02,  1.0285e-02,  1.3568e-02,  ..., -2.1436e-04,\n",
      "          3.3145e-04,  6.9002e-04]], device='cuda:0', requires_grad=True)\n",
      "min: -0.002 max: 0.022\n",
      "Parameter containing:\n",
      "tensor([-0.2848, -0.3124, -0.2516, -0.2560, -0.3290, -0.3366, -0.3669, -0.2745,\n",
      "        -0.3922, -0.3738, -0.3439, -0.3426, -0.3462, -0.3399, -0.4030, -0.2628,\n",
      "        -0.2674, -0.3926, -0.3747, -0.2488, -0.3014, -0.3583, -0.2426, -0.2944,\n",
      "        -0.2869, -0.3600, -0.4023, -0.2931, -0.3270, -0.3985, -0.2635, -0.3090,\n",
      "        -0.3772, -0.2930, -0.3478, -0.3669, -0.2993, -0.3471, -0.3927, -0.3647,\n",
      "        -0.3334, -0.3838, -0.3491, -0.3696, -0.3818, -0.3390, -0.3414, -0.3257,\n",
      "        -0.3418, -0.3287], device='cuda:0', requires_grad=True)\n",
      "min: -0.403 max: -0.243\n"
     ]
    }
   ],
   "source": [
    "for name, param in genre_classifier.named_parameters():\n",
    "    print(param)\n",
    "    min_max = (torch.min(param).to(\"cpu\").detach().item(), torch.max(param).to(\"cpu\").detach().item())\n",
    "    print(f\"min: {min_max[0]:,.3f} max: {min_max[1]:,.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_cnn = MusicCNN(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([384])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in genre_classifier.named_parameters():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object <class 'ellipsis'> should have `state_dict` method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m lr_finder \u001b[38;5;241m=\u001b[39m FastaiLRFinder()\n\u001b[1;32m      8\u001b[0m to_save \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m\"\u001b[39m: optimizer}\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m lr_finder\u001b[38;5;241m.\u001b[39mattach(trainer, to_save\u001b[38;5;241m=\u001b[39mto_save) \u001b[38;5;28;01mas\u001b[39;00m trainer_with_lr_finder:\n\u001b[1;32m     11\u001b[0m     trainer_with_lr_finder\u001b[38;5;241m.\u001b[39mrun(dataloader)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Get lr_finder results\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mugen_ml/lib/python3.9/contextlib.py:119\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/mugen_ml/lib/python3.9/site-packages/ignite/handlers/lr_finder.py:425\u001b[0m, in \u001b[0;36mFastaiLRFinder.attach\u001b[0;34m(self, trainer, to_save, output_transform, num_iter, start_lr, end_lr, step_mode, smooth_f, diverge_th)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(to_save, Mapping):\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument to_save should be a mapping, but given \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(to_save)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 425\u001b[0m \u001b[43mCheckpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_save\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstate_dict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    426\u001b[0m Checkpoint\u001b[38;5;241m.\u001b[39m_check_objects(to_save, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_state_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m to_save:\n",
      "File \u001b[0;32m~/miniconda3/envs/mugen_ml/lib/python3.9/site-packages/ignite/handlers/checkpoint.py:544\u001b[0m, in \u001b[0;36mCheckpoint._check_objects\u001b[0;34m(objs, attr)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, obj \u001b[38;5;129;01min\u001b[39;00m objs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    543\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(obj, attr):\n\u001b[0;32m--> 544\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mObject \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m should have `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object <class 'ellipsis'> should have `state_dict` method"
     ]
    }
   ],
   "source": [
    "from ignite.handlers import FastaiLRFinder\n",
    "\n",
    "trainer = ...\n",
    "model = ...\n",
    "optimizer = ...\n",
    "\n",
    "lr_finder = FastaiLRFinder()\n",
    "to_save = {\"model\": model, \"optimizer\": optimizer}\n",
    "\n",
    "with lr_finder.attach(trainer, to_save=to_save) as trainer_with_lr_finder:\n",
    "    trainer_with_lr_finder.run(dataloader)\n",
    "\n",
    "# Get lr_finder results\n",
    "lr_finder.get_results()\n",
    "\n",
    "# Plot lr_finder results (requires matplotlib)\n",
    "lr_finder.plot()\n",
    "\n",
    "# get lr_finder suggestion for lr\n",
    "lr_finder.lr_suggestion()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2 -- with small update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 8334/8334 [54:23<00:00,  2.55it/s]\n",
      "100%|████████████████████████████████████████████████████████████| 17/17 [00:04<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000 train_loss: 0.0000 val_loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 8334/8334 [54:39<00:00,  2.54it/s]\n",
      "100%|████████████████████████████████████████████████████████████| 17/17 [00:04<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001 train_loss: 0.0000 val_loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 8334/8334 [54:43<00:00,  2.54it/s]\n",
      "100%|████████████████████████████████████████████████████████████| 17/17 [00:04<00:00,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "002 train_loss: 0.0000 val_loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loses = []\n",
    "val_loses = []\n",
    "for epoch in range(3):\n",
    "    train_loss = train(model, optimizer, train_loader)\n",
    "    val_loss = validation(model, valid_loader)\n",
    "    print(f\"{epoch:03d} train_loss: {train_loss:0.4f} val_loss: {val_loss:0.4f}\")\n",
    "    train_loses.append(train_loss)\n",
    "    val_loses.append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loses, label=\"train_loses\");\n",
    "plt.plot(val_loses, label=\"val_loses\");\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1 -- diverging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 8334/8334 [54:19<00:00,  2.56it/s]\n",
      "100%|████████████████████████████████████████████████████████████| 17/17 [00:04<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000 train_loss: 0.0000 val_loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 8334/8334 [54:35<00:00,  2.54it/s]\n",
      "100%|████████████████████████████████████████████████████████████| 17/17 [00:04<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001 train_loss: 0.0000 val_loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 8334/8334 [54:34<00:00,  2.55it/s]\n",
      "100%|████████████████████████████████████████████████████████████| 17/17 [00:04<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "002 train_loss: 0.0000 val_loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 8334/8334 [54:29<00:00,  2.55it/s]\n",
      "100%|████████████████████████████████████████████████████████████| 17/17 [00:04<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "003 train_loss: 0.0000 val_loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 8334/8334 [54:29<00:00,  2.55it/s]\n",
      "100%|████████████████████████████████████████████████████████████| 17/17 [00:04<00:00,  4.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "004 train_loss: 0.0000 val_loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loses = []\n",
    "val_loses = []\n",
    "for epoch in range(5):\n",
    "    train_loss = train(model, optimizer, train_loader)\n",
    "    val_loss = validation(model, valid_loader)\n",
    "    print(f\"{epoch:03d} train_loss: {train_loss:0.4f} val_loss: {val_loss:0.4f}\")\n",
    "    train_loses.append(train_loss)\n",
    "    val_loses.append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scratchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    train_loss = train(model, optimizer, criterion, train_loader)\n",
    "    print(f\"Epoch {epoch+1}, train loss: {train_loss:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch in enumerate(top50_dataloader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.forward(sample_bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 120000])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_bs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 273024])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                     | 0/17 [00:02<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "running_loss = 0.0\n",
    "for i, (batch, genres) in tqdm(enumerate(valid_loader, 0), total=len(valid_loader)):\n",
    "    outputs = model(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([101, 12, 120])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs['x'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.music_collate_fn_wrap.<locals>.music_collate_fn(x)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mugen_ml",
   "language": "python",
   "name": "mugen_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
